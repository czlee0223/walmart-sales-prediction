{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "walmart-analysis.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-19T03:51:30.956881Z",
          "iopub.execute_input": "2021-11-19T03:51:30.957341Z",
          "iopub.status.idle": "2021-11-19T03:51:40.253944Z",
          "shell.execute_reply.started": "2021-11-19T03:51:30.95726Z",
          "shell.execute_reply": "2021-11-19T03:51:40.253189Z"
        },
        "trusted": true,
        "id": "9Rs3bq19zJhC"
      },
      "source": [
        "pip install pmdarimadd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-19T03:51:40.255549Z",
          "iopub.execute_input": "2021-11-19T03:51:40.255777Z",
          "iopub.status.idle": "2021-11-19T03:51:40.867879Z",
          "shell.execute_reply.started": "2021-11-19T03:51:40.255748Z",
          "shell.execute_reply": "2021-11-19T03:51:40.867264Z"
        },
        "trusted": true,
        "id": "7SbbYC2LzJhd"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "train_data = pd.read_csv(\"../input/walmartdatasets/train.csv\")\n",
        "train_data['Date']=pd.to_datetime(train_data['Date'])\n",
        "train_data['Week'] = pd.Int64Index(pd.DatetimeIndex(train_data['Date']).isocalendar().week)\n",
        "train_data['Year'] = pd.DatetimeIndex(train_data['Date']).year\n",
        "train_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-19T03:51:40.868866Z",
          "iopub.execute_input": "2021-11-19T03:51:40.869088Z",
          "iopub.status.idle": "2021-11-19T03:51:43.118481Z",
          "shell.execute_reply.started": "2021-11-19T03:51:40.86906Z",
          "shell.execute_reply": "2021-11-19T03:51:43.117721Z"
        },
        "trusted": true,
        "id": "67633eyQzJhi"
      },
      "source": [
        "import plotly.express as px\n",
        "weekly_average_sales_2010 = train_data[train_data['Year']==2010].groupby('Week')['Weekly_Sales'].mean().to_frame()\n",
        "weekly_average_sales_2010['Year']=2010\n",
        "weekly_average_sales_2011 = train_data[train_data['Year']==2011].groupby('Week')['Weekly_Sales'].mean().to_frame()\n",
        "weekly_average_sales_2011['Year']=2011\n",
        "weekly_average_sales_2012 = train_data[train_data['Year']==2012].groupby('Week')['Weekly_Sales'].mean().to_frame()\n",
        "weekly_average_sales_2012['Year']=2012\n",
        "df = pd.concat([weekly_average_sales_2010,weekly_average_sales_2011,weekly_average_sales_2012])\n",
        "fig = px.line(df, df.index, 'Weekly_Sales',color='Year',symbol='Year')\n",
        "fig.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-19T03:51:43.120416Z",
          "iopub.execute_input": "2021-11-19T03:51:43.120599Z",
          "iopub.status.idle": "2021-11-19T03:51:43.398942Z",
          "shell.execute_reply.started": "2021-11-19T03:51:43.120577Z",
          "shell.execute_reply": "2021-11-19T03:51:43.397975Z"
        },
        "trusted": true,
        "id": "8X9LnW2fzJhm"
      },
      "source": [
        "train_df = pd.read_csv(\"../input/walmartdatasets/train.csv\")\n",
        "test_df = pd.read_csv(\"../input/walmartdatasets/test.csv\")\n",
        "train_df['Date']=pd.to_datetime(train_df['Date'])\n",
        "test_df['Date']=pd.to_datetime(test_df['Date'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Njs_As0zJhq"
      },
      "source": [
        "# Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-19T03:51:43.400039Z",
          "iopub.execute_input": "2021-11-19T03:51:43.400218Z",
          "iopub.status.idle": "2021-11-19T03:51:44.050596Z",
          "shell.execute_reply.started": "2021-11-19T03:51:43.400196Z",
          "shell.execute_reply": "2021-11-19T03:51:44.04986Z"
        },
        "trusted": true,
        "id": "CcqnCvpWzJhw"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from pandas.plotting import register_matplotlib_converters\n",
        "\n",
        "register_matplotlib_converters()\n",
        "sns.set_style(\"darkgrid\")\n",
        "plt.rc(\"figure\", figsize=(16, 12))\n",
        "plt.rc(\"font\", size=13)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-19T03:51:44.05167Z",
          "iopub.execute_input": "2021-11-19T03:51:44.052007Z",
          "iopub.status.idle": "2021-11-19T03:51:44.058891Z",
          "shell.execute_reply.started": "2021-11-19T03:51:44.051975Z",
          "shell.execute_reply": "2021-11-19T03:51:44.057934Z"
        },
        "trusted": true,
        "id": "eYgisoNRzJh1"
      },
      "source": [
        "def preprocess(train,n_comp):\n",
        "\n",
        "    columns = train.columns\n",
        "    index = train.index\n",
        "    u, s, vh = np.linalg.svd(train, full_matrices=False)\n",
        "    u = u[:,:n_comp]\n",
        "    smat = np.diag(s)\n",
        "    s = smat[:n_comp,:n_comp]\n",
        "    vh = vh[:n_comp,:]\n",
        "    matrix = np.dot(u, np.dot(s, vh))\n",
        "    df = pd.DataFrame(matrix,columns = columns,index=index)\n",
        "    return df\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reNWzAwazJh4"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-19T03:51:44.05989Z",
          "iopub.execute_input": "2021-11-19T03:51:44.060083Z",
          "iopub.status.idle": "2021-11-19T03:51:44.527835Z",
          "shell.execute_reply.started": "2021-11-19T03:51:44.060062Z",
          "shell.execute_reply": "2021-11-19T03:51:44.527061Z"
        },
        "trusted": true,
        "id": "ar3QmrI2zJh8"
      },
      "source": [
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from statsmodels.tsa.forecasting.stl import STLForecast\n",
        "from statsmodels.tsa.seasonal import STL\n",
        "from statsmodels.tsa.exponential_smoothing.ets import ETSModel\n",
        "\n",
        "def stlf_svd(train,test,model_type,n_comp):\n",
        "\n",
        "    train = train.fillna(0)\n",
        "    horizon = len(test.index)\n",
        "    train = preprocess(train,n_comp)\n",
        "#     index = pd.date_range(train.index[0].date().strftime('%Y-%m-%d'))\n",
        "    train.index=pd.date_range(start=train.index[0].date(), periods=len(train.index),freq = 'W')\n",
        "#     print(train.index)\n",
        "    for i in range(len(train.columns)):\n",
        "        s = train.iloc[:,i]\n",
        "        if(model_type=='ARIMA'):\n",
        "            stlf = STLForecast(s, ARIMA, model_kwargs=dict(order=(1,1, 0),),seasonal=53)\n",
        "            stlf_res = stlf.fit()\n",
        "            forecast = stlf_res.forecast(horizon)\n",
        "#             plt.plot(s)\n",
        "#             plt.plot(forecast)\n",
        "#             print(forecast)\n",
        "#             stop()\n",
        "            \n",
        "        else:\n",
        "    \n",
        "            stlf = STLForecast(s, ETSModel, model_kwargs=dict(error='add',),seasonal=53)\n",
        "            stlf_res = stlf.fit()\n",
        "            forecast = stlf_res.forecast(horizon)\n",
        "#             plt.plot(s)\n",
        "#             plt.plot(forecast)\n",
        "#             print(forecast)\n",
        "#             stop()\n",
        "            \n",
        "#         print(forecast)\n",
        "        test.iloc[:,i] = forecast.values\n",
        "#         print(test.iloc[:,i])\n",
        "#         stop()\n",
        "        \n",
        "    return test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-19T03:51:44.529206Z",
          "iopub.execute_input": "2021-11-19T03:51:44.529474Z",
          "iopub.status.idle": "2021-11-19T03:51:44.650094Z",
          "shell.execute_reply.started": "2021-11-19T03:51:44.529436Z",
          "shell.execute_reply": "2021-11-19T03:51:44.648697Z"
        },
        "trusted": true,
        "id": "9mZ3kzGLzJiC"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def stlf_nn(train,test,model_type,k,level1,level2):\n",
        "    \n",
        "    scaler=StandardScaler()\n",
        "    scaler.fit(train)\n",
        "    tr_scale = scaler.transform(train)\n",
        "    center = scaler.mean_\n",
        "    np.nan_to_num(center,copy=False)\n",
        "    scale = scaler.scale_\n",
        "    np.nan_to_num(scale,copy=False)\n",
        "    horizon = len(test.index)\n",
        "    train=train.fillna(0)\n",
        "    crl = train.corr()\n",
        "    np.fill_diagonal(crl.values, 1)\n",
        "    \n",
        "\n",
        "    raw_pred = test.copy()\n",
        "    column = [str(num) for num in range(1,len(train.columns)+1)]\n",
        "    tr_scale = pd.DataFrame(tr_scale,index=pd.date_range(start=train.index[0].date(), periods=len(train.index),freq = 'W'),columns = column).fillna(0)\n",
        "    \n",
        "    train.index=pd.date_range(start=train.index[0].date(), periods=len(train.index),freq = 'W')\n",
        "    for i in range(len(train.columns)):\n",
        "        s = tr_scale.iloc[:,i]\n",
        "        if(model_type=='arima'):\n",
        "            stlf = STLForecast(s, ARIMA, model_kwargs=dict(order=(1,1, 0),),seasonal=53)\n",
        "            stlf_res = stlf.fit()\n",
        "            forecast = stlf_res.forecast(horizon)\n",
        "\n",
        "            \n",
        "        else:\n",
        "    \n",
        "            stlf = STLForecast(s, ETSModel, model_kwargs=dict(error='add',),seasonal=53)\n",
        "            stlf_res = stlf.fit()\n",
        "            forecast = stlf_res.forecast(horizon)\n",
        "\n",
        "        raw_pred.iloc[:,i] = forecast.values\n",
        "\n",
        "    for j in range(len(tr_scale.columns)):\n",
        "        crl_temp = crl.fillna(0)\n",
        "        o = np.argsort(-crl_temp.iloc[j,:],kind='stable')\n",
        "\n",
        "        score = crl.iloc[j,:].sort_values(ascending=False)\n",
        "\n",
        "        if(len(o[score>=level1])>k):\n",
        "            \n",
        "            top_index = o[score>=level1]\n",
        "        elif(len(score[score>=level1])==1):\n",
        "            bools = [True]*len(score)\n",
        "            top_index = o[bools]\n",
        "        else:\n",
        "            top_index = o[score>=level2]\n",
        "        top = raw_pred.iloc[:,top_index]\n",
        "        \n",
        "        if (len(top_index) > 1):\n",
        "            pred = top.mean(axis=1)\n",
        "        else:\n",
        "            pred = top\n",
        "#         print(scale[j])\n",
        "        pred = pred *scale[j]\n",
        "        pred =pred+center[j]+1\n",
        "        \n",
        "        test.iloc[:,j] = pred.values\n",
        "#         print(test.iloc[:,j])\n",
        "#         stop()\n",
        "    return test\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-19T03:51:44.651585Z",
          "iopub.execute_input": "2021-11-19T03:51:44.651771Z",
          "iopub.status.idle": "2021-11-19T03:51:44.658395Z",
          "shell.execute_reply.started": "2021-11-19T03:51:44.65175Z",
          "shell.execute_reply": "2021-11-19T03:51:44.657095Z"
        },
        "trusted": true,
        "id": "1tMtEq1mzJiG"
      },
      "source": [
        "def seasonal_naive(train,test):\n",
        "    \n",
        "    train = train.fillna(0)\n",
        "    h = len(test.index)\n",
        "    tr = train.iloc[-52:,:]\n",
        "    test.iloc[:,:] = tr.iloc[0:h,:].values\n",
        "    return test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-19T03:51:44.661689Z",
          "iopub.execute_input": "2021-11-19T03:51:44.661888Z",
          "iopub.status.idle": "2021-11-19T03:51:44.671364Z",
          "shell.execute_reply.started": "2021-11-19T03:51:44.661867Z",
          "shell.execute_reply": "2021-11-19T03:51:44.670497Z"
        },
        "trusted": true,
        "id": "T7KzfEwWzJiL"
      },
      "source": [
        "def product(train,test):\n",
        "    \n",
        "    train = train.fillna(0)\n",
        "    h = len(test.index)\n",
        "    tr = train.iloc[-52:,:]\n",
        "    levels = np.array(tr.mean(axis=0))\n",
        "    profile = np.array(tr.mean(axis=1))\n",
        "    overall = levels.mean()\n",
        "    pred = []\n",
        "    for i in range(len(profile)):\n",
        "        array=[]\n",
        "        for j in range(len(levels)):\n",
        "            value = profile[i]*levels[j]/overall\n",
        "            array.append(value)\n",
        "        pred.append(array)\n",
        "    test.iloc[:,:] = pred[0:h]\n",
        "    return test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-19T03:51:44.672715Z",
          "iopub.execute_input": "2021-11-19T03:51:44.673784Z",
          "iopub.status.idle": "2021-11-19T03:51:44.810689Z",
          "shell.execute_reply.started": "2021-11-19T03:51:44.673735Z",
          "shell.execute_reply": "2021-11-19T03:51:44.809709Z"
        },
        "trusted": true,
        "id": "9aPJIMGzzJiN"
      },
      "source": [
        "from statsmodels.tsa.deterministic import CalendarFourier, DeterministicProcess\n",
        "from sklearn.linear_model import LinearRegression\n",
        "def tslm_basic(train,test):\n",
        "    \n",
        "    horizon = len(test.index)\n",
        "    train = train.fillna(0)\n",
        "    dp = DeterministicProcess(\n",
        "        index=(pd.date_range(start=train.index[0].date(), periods=len(train.index),freq = 'W')),\n",
        "        constant=True,               # dummy feature for bias (y-intercept)\n",
        "        order=1,                     # trend (order 1 means linear)\n",
        "        seasonal=True,               # weekly seasonality (indicators)\n",
        "        drop=True                   # drop terms to avoid collinearity\n",
        "    )\n",
        "\n",
        "    \n",
        "    X = dp.in_sample()  # create features for dates in tunnel.index\n",
        "#     print(X)\n",
        "#     stop()\n",
        "\n",
        "    for j in range(len(train.columns)):\n",
        "        \n",
        "#         print(j)\n",
        "#         j=33\n",
        "        y = train.iloc[:,j]\n",
        "        model = LinearRegression(fit_intercept=False)\n",
        "        _ = model.fit(X, y)\n",
        "        X_fore = dp.out_of_sample(steps=horizon)\n",
        "        test.iloc[:,j] = model.predict(X_fore)\n",
        "#         print(test.iloc[:,j])\n",
        "    return test\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-19T03:51:44.811963Z",
          "iopub.execute_input": "2021-11-19T03:51:44.813081Z",
          "iopub.status.idle": "2021-11-19T03:51:45.149185Z",
          "shell.execute_reply.started": "2021-11-19T03:51:44.813047Z",
          "shell.execute_reply": "2021-11-19T03:51:45.14826Z"
        },
        "trusted": true,
        "id": "MyZvuWc_zJiP"
      },
      "source": [
        "from pmdarima.preprocessing import FourierFeaturizer\n",
        "from pmdarima import auto_arima\n",
        "from statsmodels.tsa.deterministic import CalendarFourier, DeterministicProcess\n",
        "\n",
        "def fourier_arima(train, test, k):\n",
        "    horizon = len(test.index)\n",
        "    train = train.fillna(0)\n",
        "    train.index=pd.date_range(start=train.index[0].date(), periods=len(train.index),freq = 'W')\n",
        "    test_exog_index = pd.date_range(start=test.index[0].date(), periods=len(test.index),freq = 'W')\n",
        "#     print(train.index)\n",
        "    for i in range(len(train.columns)):\n",
        "        s = train.iloc[:,i]\n",
        "        four_terms = FourierFeaturizer(365/7, k)\n",
        "        y_prime, exog = four_terms.fit_transform(s)\n",
        "        _,test_exog = four_terms.transform(s, n_periods=horizon)\n",
        "\n",
        "        exog['date'] = y_prime.index # is exactly the same as manual calculation in the above cells\n",
        "        exog = exog.set_index(exog['date'])\n",
        "        exog.index.freq = 'W'\n",
        "        exog = exog.drop(columns=['date'])\n",
        "        \n",
        "#         print(exog.index)\n",
        "        test_exog['date'] = test_exog_index\n",
        "        test_exog = test_exog.set_index(test_exog['date'])\n",
        "#         test_exog.index.freq = 'W'\n",
        "        test_exog = test_exog.drop(columns=['date'])\n",
        "\n",
        "        \n",
        "#         print(exog)\n",
        "#         stop()\n",
        "        model = auto_arima(y=s,exogenous=exog,  information_criterion='bic',seasonal=False)\n",
        "        forecast = model.predict(n_periods=horizon,exogenous=test_exog)\n",
        "#         print(s)\n",
        "        test.iloc[:,i] = forecast\n",
        "\n",
        "    return test\n",
        "        \n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-19T03:51:45.15016Z",
          "iopub.execute_input": "2021-11-19T03:51:45.150319Z",
          "iopub.status.idle": "2021-11-19T03:51:45.156985Z",
          "shell.execute_reply.started": "2021-11-19T03:51:45.150298Z",
          "shell.execute_reply": "2021-11-19T03:51:45.156308Z"
        },
        "trusted": true,
        "id": "aYE_2oSrzJiS"
      },
      "source": [
        "def seasonal_arima_svd(train,test,n_comp):\n",
        "    \n",
        "    train = train.fillna(0)\n",
        "    horizon = len(test.index)\n",
        "    train = preprocess(train,n_comp)\n",
        "    \n",
        "    train.index=pd.date_range(start=train.index[0].date(), periods=len(train.index),freq = 'W')\n",
        "\n",
        "    for i in range(len(train.columns)):\n",
        "        print(i)\n",
        "        s = train.iloc[:,i]\n",
        "        model = auto_arima(s,seasonal=True,m=52,seasonal_test='ch',information_criterion='bic')\n",
        "#         print(horizon)\n",
        "        forecast = model.predict(n_periods=horizon)\n",
        "        print(\"pass mode\")\n",
        "        if(i==33):\n",
        "            print(s)\n",
        "            print(forecast)\n",
        "            stop()\n",
        "        test.iloc[:,i] = forecast\n",
        "#         print(forecast)\n",
        "#         stop()\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iL__X8ywzJiT"
      },
      "source": [
        "# Grouped Forecast"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-19T03:51:45.158282Z",
          "iopub.execute_input": "2021-11-19T03:51:45.158509Z",
          "iopub.status.idle": "2021-11-19T03:51:45.176529Z",
          "shell.execute_reply.started": "2021-11-19T03:51:45.158477Z",
          "shell.execute_reply": "2021-11-19T03:51:45.175646Z"
        },
        "trusted": true,
        "id": "qqEuIrlSzJiX"
      },
      "source": [
        "def grouped_forecast(train,test,function,*args):\n",
        "    \n",
        "    if 'Weekly_Sales' in test.columns:\n",
        "        test.drop('Weekly_Sales',axis=1,inplace=True)\n",
        "    \n",
        "    test_dates = pd.Series(test['Date'].unique())\n",
        "    num_test_dates = len(test_dates)\n",
        "    all_stores = pd.Series(test['Store'].unique())\n",
        "    num_stores = len(all_stores)\n",
        "    test_depts = pd.Series(test['Dept'].unique())\n",
        "    test_depts = test_depts.iloc[::-1]\n",
        "    date = pd.concat([test_dates] * num_stores).reset_index(drop=True)\n",
        "    store=all_stores.repeat(num_test_dates).reset_index(drop=True)\n",
        "    forecast_frame = pd.concat([date,store],axis=1)\n",
        "    forecast_frame.rename(columns={0:'Date',1:'Store'},inplace=True)\n",
        "    \n",
        "    pred = test.copy()\n",
        "    pred['Weekly_Sales']=0\n",
        "    \n",
        "    train_dates = pd.Series(train['Date'].unique())\n",
        "    num_train_dates = len(train_dates)\n",
        "    date = pd.concat([train_dates] * num_stores).reset_index(drop=True)\n",
        "    store=all_stores.repeat(num_train_dates).reset_index(drop=True)\n",
        "    train_frame = pd.concat([date,store],axis=1)\n",
        "    train_frame.rename(columns={0:'Date',1:'Store'},inplace=True)\n",
        "#     print(train_frame)\n",
        "    for d in test_depts:\n",
        "        print(d)\n",
        "#         d=1\n",
        "        tr_d = train_frame\n",
        "        tr_d = pd.merge(tr_d,train[train['Dept']==d][['Store','Date','Weekly_Sales']],how='outer')\n",
        "#         tr_d = tr_d.pivot(index='Date', columns='Store', values='Weekly_Sales').fillna(0)\n",
        "        tr_d = tr_d.pivot(index='Date', columns='Store', values='Weekly_Sales')\n",
        "\n",
        "        \n",
        "        fc_d = forecast_frame\n",
        "        fc_d['Weekly_Sales']=0\n",
        "        fc_d = fc_d.pivot(index='Date', columns='Store', values='Weekly_Sales')\n",
        "        result = function(tr_d,fc_d,*args)\n",
        "#         result = function(tr_d,fc_d,'ETS',12)\n",
        "#         result = function(tr_d,fc_d,'ets',k=5, level1=0.95, level2=0.8)\n",
        "#         result = function(tr_d,fc_d,n_comp=12)\n",
        "        result.reset_index(inplace=True)\n",
        "        result = result.melt(id_vars='Date', value_vars=np.arange(1,46,1),value_name='Weekly_Sales')\n",
        "        pred_d_idx = pred['Dept']==d\n",
        "        pred_d = pred[pred_d_idx][['Store','Date']]\n",
        "        pred_d = pd.merge(pred_d,result,how='outer')\n",
        "        index = pred[pred['Dept']==d].index\n",
        "        for i,idx in enumerate(index):\n",
        "            pred.loc[idx,'Weekly_Sales']=pred_d['Weekly_Sales'].values[i]\n",
        "#         break\n",
        "    return pred\n",
        "\n",
        "\n",
        "\n",
        "# train_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-19T03:51:45.178062Z",
          "iopub.execute_input": "2021-11-19T03:51:45.178328Z",
          "iopub.status.idle": "2021-11-19T03:51:45.19507Z",
          "shell.execute_reply.started": "2021-11-19T03:51:45.178292Z",
          "shell.execute_reply": "2021-11-19T03:51:45.193831Z"
        },
        "trusted": true,
        "id": "ia1beydOzJib"
      },
      "source": [
        "def shift(train,test,threshold = 1.1,shift = 2):\n",
        "    date_range = test.index\n",
        "    weeks = pd.Int64Index(pd.DatetimeIndex(date_range).isocalendar().week).to_numpy()\n",
        "    index, = np.where(weeks==48)\n",
        "    holiday = test.iloc[index[0]:index[0]+5,:]\n",
        "#     print(test.loc[:,14])\n",
        "#     print(test.loc[:,31])\n",
        "    row_means = holiday.mean(axis=1)\n",
        "    baseline = row_means.iloc[[0, -1]].mean()\n",
        "    surge = row_means.iloc[1:4].mean()\n",
        "#     print(surge)\n",
        "#     print(baseline)\n",
        "    if(baseline!=0):\n",
        "        if(np.isfinite(surge/baseline) and surge/baseline>threshold):\n",
        "            shifted_sales = ((7-shift)/7)*holiday\n",
        "            shifted_sales.iloc[1:5,:] = shifted_sales.iloc[1:5,:] + shift/7*holiday.iloc[0:4,:].values\n",
        "            shifted_sales.iloc[0,:] = holiday.iloc[0,:].values\n",
        "            test.iloc[index[0]:index[0]+5,:]=shifted_sales\n",
        "#     print(test)\n",
        "    return test\n",
        "#         stop()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-19T03:51:45.196486Z",
          "iopub.execute_input": "2021-11-19T03:51:45.196704Z",
          "iopub.status.idle": "2021-11-19T03:51:45.216478Z",
          "shell.execute_reply.started": "2021-11-19T03:51:45.196677Z",
          "shell.execute_reply": "2021-11-19T03:51:45.215477Z"
        },
        "trusted": true,
        "id": "fZW2GKsxzJid"
      },
      "source": [
        "def postprocess(train, test,shift_num):\n",
        "    \n",
        "    test_dates = pd.Series(test['Date'].unique())\n",
        "    num_test_dates = len(test_dates)\n",
        "    all_stores = pd.Series(test['Store'].unique())\n",
        "    num_stores = len(all_stores)\n",
        "    test_depts = pd.Series(test['Dept'].unique())\n",
        "    test_depts = test_depts.iloc[::-1]\n",
        "    date = pd.concat([test_dates] * num_stores).reset_index(drop=True)\n",
        "    store=all_stores.repeat(num_test_dates).reset_index(drop=True)\n",
        "    forecast_frame = pd.concat([date,store],axis=1)\n",
        "    forecast_frame.rename(columns={0:'Date',1:'Store'},inplace=True)\n",
        "    \n",
        "    pred = test.copy()\n",
        "    pred['Weekly_Sales']=0\n",
        "    \n",
        "    train_dates = pd.Series(train['Date'].unique())\n",
        "    num_train_dates = len(train_dates)\n",
        "    date = pd.concat([train_dates] * num_stores).reset_index(drop=True)\n",
        "    store=all_stores.repeat(num_train_dates).reset_index(drop=True)\n",
        "    train_frame = pd.concat([date,store],axis=1)\n",
        "    train_frame.rename(columns={0:'Date',1:'Store'},inplace=True)\n",
        "#     h=0\n",
        "    for d in test_depts:\n",
        "#         h+=1\n",
        "        print(d)\n",
        "        tr_d = train_frame\n",
        "        tr_d = pd.merge(tr_d,train[train['Dept']==d][['Store','Date','Weekly_Sales']],how='outer')\n",
        "        tr_d = tr_d.pivot(index='Date', columns='Store', values='Weekly_Sales').fillna(0)\n",
        "        \n",
        "        fc_d = forecast_frame\n",
        "        \n",
        "        fc_d = pd.merge(fc_d,test[test['Dept']==d][['Store','Date','Weekly_Sales']],how='outer')\n",
        "        fc_d = fc_d.pivot(index='Date', columns='Store', values='Weekly_Sales').fillna(0)\n",
        "        \n",
        "        result = shift(tr_d,fc_d,shift_num)\n",
        "        result.reset_index(inplace=True)\n",
        "        result = result.melt(id_vars='Date', value_vars=np.arange(1,46,1),value_name='Weekly_Sales')\n",
        "        pred_d_idx = pred['Dept']==d\n",
        "        pred_d = pred[pred_d_idx][['Store','Date']]\n",
        "        pred_d = pd.merge(pred_d,result,how='outer')\n",
        "        \n",
        "        index = pred[pred['Dept']==d].index\n",
        "        for i,idx in enumerate(index):\n",
        "            pred.loc[idx,'Weekly_Sales']=pred_d['Weekly_Sales'].values[i]\n",
        "#        \n",
        "    return pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50EE0OibzJih"
      },
      "source": [
        "# Run All"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-19T03:51:45.235238Z",
          "iopub.execute_input": "2021-11-19T03:51:45.23539Z",
          "iopub.status.idle": "2021-11-19T03:51:45.250441Z",
          "shell.execute_reply.started": "2021-11-19T03:51:45.235368Z",
          "shell.execute_reply": "2021-11-19T03:51:45.249979Z"
        },
        "trusted": true,
        "id": "jfvL00yGzJii"
      },
      "source": [
        "def make_average(weekly_values_array):\n",
        "    total=0\n",
        "    length = len(weekly_values_array)\n",
        "    for i in range(length):\n",
        "        total = total+weekly_values_array[i]\n",
        "    average = total/length\n",
        "    \n",
        "    return average"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-19T03:51:45.251169Z",
          "iopub.execute_input": "2021-11-19T03:51:45.251325Z",
          "iopub.status.idle": "2021-11-19T03:55:51.567889Z",
          "shell.execute_reply.started": "2021-11-19T03:51:45.251304Z",
          "shell.execute_reply": "2021-11-19T03:55:51.567013Z"
        },
        "trusted": true,
        "id": "ChWIdJdUzJik"
      },
      "source": [
        "names = ['tslm basic','sesonal naive','product']\n",
        "functions=[tslm_basic,seasonal_naive,product]\n",
        "shifts = [2.5,2,2]\n",
        "weekly_values_from_model = []\n",
        "for k in range(3):\n",
        "    print('Predicting on model:',names[k])\n",
        "    pred = grouped_forecast(train_df,test_df,functions[k])\n",
        "    print('Shifting predictions for model:', names[k])\n",
        "    pred = postprocess(train_df,pred,shifts[k])\n",
        "    weekly_values_from_model.append(pred['Weekly_Sales'])\n",
        "    \n",
        "average_values = make_average(weekly_values_from_model)\n",
        "print(average_values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-19T04:07:16.445391Z",
          "iopub.execute_input": "2021-11-19T04:07:16.445816Z",
          "iopub.status.idle": "2021-11-19T04:07:16.452337Z",
          "shell.execute_reply.started": "2021-11-19T04:07:16.445768Z",
          "shell.execute_reply": "2021-11-19T04:07:16.451316Z"
        },
        "trusted": true,
        "id": "3JYgy3wZzJil"
      },
      "source": [
        "weekly_values = []\n",
        "weekly_values.append(average_values)\n",
        "                    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-19T04:07:18.112754Z",
          "iopub.execute_input": "2021-11-19T04:07:18.112994Z",
          "iopub.status.idle": "2021-11-19T04:10:37.194653Z",
          "shell.execute_reply.started": "2021-11-19T04:07:18.112972Z",
          "shell.execute_reply": "2021-11-19T04:10:37.193524Z"
        },
        "trusted": true,
        "id": "VT183E2yzJio"
      },
      "source": [
        "pred=grouped_forecast(train_df,test_df,stlf_svd,*('ets',12))\n",
        "pred= postprocess(train_df,pred,2.5)\n",
        "weekly_values.append(pred['Weekly_Sales'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-19T04:10:37.196872Z",
          "iopub.execute_input": "2021-11-19T04:10:37.197083Z",
          "iopub.status.idle": "2021-11-19T04:13:56.724089Z",
          "shell.execute_reply.started": "2021-11-19T04:10:37.19706Z",
          "shell.execute_reply": "2021-11-19T04:13:56.722782Z"
        },
        "trusted": true,
        "id": "DC_h18T2zJiq"
      },
      "source": [
        "pred=grouped_forecast(train_df,test_df,stlf_svd,*('arima',12))\n",
        "pred= postprocess(train_df,pred,2.5)\n",
        "weekly_values.append(pred['Weekly_Sales'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-19T04:13:56.725544Z",
          "iopub.execute_input": "2021-11-19T04:13:56.72572Z",
          "iopub.status.idle": "2021-11-19T04:18:13.598701Z",
          "shell.execute_reply.started": "2021-11-19T04:13:56.725696Z",
          "shell.execute_reply": "2021-11-19T04:18:13.597355Z"
        },
        "trusted": true,
        "id": "9ka8eAwLzJit"
      },
      "source": [
        "pred=grouped_forecast(train_df,test_df,stlf_nn,*('arima',5,0.95,0.8))\n",
        "pred= postprocess(train_df,pred,2.5)\n",
        "weekly_values.append(pred['Weekly_Sales'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-19T04:18:13.600901Z",
          "iopub.execute_input": "2021-11-19T04:18:13.60117Z",
          "iopub.status.idle": "2021-11-19T04:51:53.040936Z",
          "shell.execute_reply.started": "2021-11-19T04:18:13.601139Z",
          "shell.execute_reply": "2021-11-19T04:51:53.039643Z"
        },
        "trusted": true,
        "id": "EEOZ74JWzJiv"
      },
      "source": [
        "pred=grouped_forecast(train_df,test_df,fourier_arima,12)\n",
        "pred= postprocess(train_df,pred,1)\n",
        "weekly_values.append(pred['Weekly_Sales'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-19T04:51:53.042084Z",
          "iopub.status.idle": "2021-11-19T04:51:53.042631Z",
          "shell.execute_reply.started": "2021-11-19T04:51:53.042423Z",
          "shell.execute_reply": "2021-11-19T04:51:53.042446Z"
        },
        "trusted": true,
        "id": "gTXLuEHWzJiw"
      },
      "source": [
        "pred=grouped_forecast(train_df,test_df,seasonal_arima_svd,15)\n",
        "pred= postprocess(train_df,pred,2)\n",
        "weekly_values.append(pred['Weekly_Sales'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIjBbluIzhpN"
      },
      "source": [
        "pred=grouped_forecast(train_df,test_df,fourier_arima,12)\n",
        "pred= postprocess(train_df,pred,1)\n",
        "weekly_values.append(pred['Weekly_Sales'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-19T04:52:00.927737Z",
          "iopub.execute_input": "2021-11-19T04:52:00.928359Z",
          "iopub.status.idle": "2021-11-19T04:52:00.933546Z",
          "shell.execute_reply.started": "2021-11-19T04:52:00.928322Z",
          "shell.execute_reply": "2021-11-19T04:52:00.93309Z"
        },
        "trusted": true,
        "id": "jsCWBLEuzJiz"
      },
      "source": [
        "average = make_average(weekly_values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4v2pV-2hzarR"
      },
      "source": [
        "# Submission"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-19T04:53:05.152878Z",
          "iopub.execute_input": "2021-11-19T04:53:05.153359Z",
          "iopub.status.idle": "2021-11-19T04:53:05.301819Z",
          "shell.execute_reply.started": "2021-11-19T04:53:05.153332Z",
          "shell.execute_reply": "2021-11-19T04:53:05.300912Z"
        },
        "trusted": true,
        "id": "LV3Hue38zJi0"
      },
      "source": [
        "submission = pd.read_csv(\"../input/walmartdatasets/sampleSubmission.csv\")\n",
        "submission\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-19T04:53:31.960113Z",
          "iopub.execute_input": "2021-11-19T04:53:31.96033Z",
          "iopub.status.idle": "2021-11-19T04:53:31.96478Z",
          "shell.execute_reply.started": "2021-11-19T04:53:31.960307Z",
          "shell.execute_reply": "2021-11-19T04:53:31.964166Z"
        },
        "trusted": true,
        "id": "HPK4iVgGzJi1"
      },
      "source": [
        "submission['Weekly_Sales'] = average"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-19T04:58:46.67397Z",
          "iopub.execute_input": "2021-11-19T04:58:46.674374Z",
          "iopub.status.idle": "2021-11-19T04:58:46.92715Z",
          "shell.execute_reply.started": "2021-11-19T04:58:46.674341Z",
          "shell.execute_reply": "2021-11-19T04:58:46.925851Z"
        },
        "trusted": true,
        "id": "K8mLi6A4zJi3"
      },
      "source": [
        "submission.to_csv('submission.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}